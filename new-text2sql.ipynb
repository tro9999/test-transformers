{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee412aa2-90ab-4fff-b672-5786b3bab7e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e92ef1fe-3ee3-4b97-ad20-1af804d112b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-13 11:41:34.161226: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-13 11:41:35.060444: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8955c178-5dde-47a1-a59b-ccddef808f4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acc3fd4a-62cb-40a2-b90e-1a5e00a81bd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define Dataset Class\n",
    "class SQLDataset(Dataset):\n",
    "    def __init__(self, data_path, tokenizer):\n",
    "        self.data = self.load_data(data_path)\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item = self.data[index]\n",
    "        question = item[\"question\"]\n",
    "        sql = item[\"answer\"]  # Assuming the SQL syntax is stored in the \"answer\" attribute\n",
    "\n",
    "        encoded_inputs = self.tokenizer.encode_plus(\n",
    "            question,\n",
    "            sql,\n",
    "            padding=\"max_length\",\n",
    "            max_length=128,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        input_ids = encoded_inputs[\"input_ids\"].squeeze()\n",
    "        attention_mask = encoded_inputs[\"attention_mask\"].squeeze()\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"labels\": torch.tensor(1 if sql else 0),\n",
    "        }\n",
    "\n",
    "    def load_data(self, data_path):\n",
    "        with open(data_path, \"r\") as file:\n",
    "            data = json.load(file)\n",
    "        return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f76bccc1-67d3-4d67-9fc4-bd4f286452ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Function to Compute Metrics\n",
    "def compute_metrics(labels, preds):\n",
    "    preds = torch.argmax(preds, dim=1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    report = classification_report(labels, preds)\n",
    "    return {\"accuracy\": acc, \"classification_report\": report}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46c1af35-406a-4105-a570-75ef873365f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set Paths\n",
    "train_data_path = \"sqlData-train.json\"\n",
    "test_data_path = \"sqlData-test.json\"\n",
    "output_dir = \"./fine_tuned_model\"\n",
    "\n",
    "# Set Hyperparameters\n",
    "batch_size = 16\n",
    "learning_rate = 2e-5\n",
    "num_epochs = 3\n",
    "num_labels = 2\n",
    "\n",
    "# Load Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf3aa601-4579-4f27-ab8e-a400d3fb4bf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "train_dataset = SQLDataset(train_data_path, tokenizer)\n",
    "test_dataset = SQLDataset(test_data_path, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4405a2cf-e78e-4c82-9164-aa656e139117",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Data Loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d4e8bd-5269-4863-8c7c-d5e803ec9b7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load BERT Model\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=num_labels,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3d303cb-0047-411c-868d-1b840a91c967",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Optimizer and Scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8feb48bd-e330-4ee4-8ae8-79cbc0069da3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 - Average Loss: 0.1090\n",
      "Epoch 2/3 - Average Loss: 0.0023\n",
      "Epoch 3/3 - Average Loss: 0.0008\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels,\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs} - Average Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c013f96e-1a15-4af8-a7c3-c5d0acf71c43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./fine_tuned_model/tokenizer_config.json',\n",
       " './fine_tuned_model/special_tokens_map.json',\n",
       " './fine_tuned_model/vocab.txt',\n",
       " './fine_tuned_model/added_tokens.json')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the fine-tuned model\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68e17fb2-09c4-476c-8b20-63921d0deca6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Loss: 0.0005\n",
      "Accuracy: 1.0000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       119\n",
      "\n",
      "    accuracy                           1.00       119\n",
      "   macro avg       1.00      1.00      1.00       119\n",
      "weighted avg       1.00      1.00      1.00       119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "eval_loss = 0\n",
    "preds = []\n",
    "labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        batch_labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=batch_labels,\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        eval_loss += loss.item()\n",
    "        preds.append(logits.detach().cpu())\n",
    "        labels.append(batch_labels.detach().cpu())\n",
    "\n",
    "eval_loss /= len(test_loader)\n",
    "preds = torch.cat(preds, dim=0)\n",
    "labels = torch.cat(labels, dim=0)\n",
    "\n",
    "metrics = compute_metrics(labels, preds)\n",
    "accuracy = metrics[\"accuracy\"]\n",
    "classification_report = metrics[\"classification_report\"]\n",
    "\n",
    "print(f\"\\nEvaluation Loss: {eval_loss:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"\\nClassification Report:\\n{classification_report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7c7a2e1-c30b-497f-8661-690e4acb1d03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"fine_tuned_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14862e80-fd68-42ba-b02d-9d67dc33b381",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"fine_tuned_model\")\n",
    "input_text = \"How much deep sleep I got last night?\"\n",
    "encoded_input = tokenizer.encode_plus(\n",
    "    input_text,\n",
    "    padding=\"max_length\",\n",
    "    max_length=128,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ae5ebab-5c29-4ed4-8e7a-40d647bdc75a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    input_ids = encoded_input[\"input_ids\"]\n",
    "    attention_mask = encoded_input[\"attention_mask\"]\n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "predicted_class = torch.argmax(outputs.logits, dim=1).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfd04e09-ca5e-4650-99bc-c1e3c580f0a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c42b626-6daa-44f8-b8f0-be1dfd80d37a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
